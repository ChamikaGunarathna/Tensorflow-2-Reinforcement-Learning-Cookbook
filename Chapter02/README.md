### Chapter 2: Implementing value-based, policy gradients and actor-critic Deep RL algorithms

- 2.1 Building stochastic environments for training RL agents

- [2.2 Building value-based Reinforcement Learning agent algorithms](https://github.com/PacktPublishing/Tensorflow-2-Reinforcement-Learning-Cookbook/blob/master/Chapter02/2_value_based_rl.py)

- [2.3 Implementing Temporal Difference (TD) Learning](https://github.com/PacktPublishing/Tensorflow-2-Reinforcement-Learning-Cookbook/blob/master/Chapter02/3_temporal_difference_learning.py)

- [2.4 Building Monte-Carlo prediction and control for RL](https://github.com/PacktPublishing/Tensorflow-2-Reinforcement-Learning-Cookbook/blob/master/Chapter02/4_monte_carlo_prediction_and_control_rl.py)

- [2.5 Implementing SARSA algorithm and SARSA agent](https://github.com/PacktPublishing/Tensorflow-2-Reinforcement-Learning-Cookbook/blob/master/Chapter02/5_sarsa_sarsa_lambda.py)

- [2.6 Building a Q-Learning agent](https://github.com/PacktPublishing/Tensorflow-2-Reinforcement-Learning-Cookbook/blob/master/Chapter02/6_q_learning.py)

- [2.7 Implementing Policy Gradients (PG) and a PG agent](https://github.com/PacktPublishing/Tensorflow-2-Reinforcement-Learning-Cookbook/blob/master/Chapter02/7_policy_gradients.py)

- [2.8 Implementing Actor-Critic Algorithms and agent](https://github.com/PacktPublishing/Tensorflow-2-Reinforcement-Learning-Cookbook/blob/master/Chapter02/8_actor_critic_agent.py)
