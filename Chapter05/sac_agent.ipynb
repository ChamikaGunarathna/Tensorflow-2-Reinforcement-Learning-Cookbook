{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Soft Actor-Critic (SAC) agent training scripta for stock market trading\n",
    "Chapter 5, TensorFlow 2 Reinforcement Learning Cookbook | Praveen Palanisamy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import functools\n",
    "import os\n",
    "import random\n",
    "from collections import deque\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow.keras.layers import Concatenate, Dense, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stock_trading_continuous_env import StockTradingContinuousEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.set_floatx(\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def actor(state_shape, action_shape, units=(512, 256, 64)):\n",
    "    state_shape_flattened = functools.reduce(lambda x, y: x * y, state_shape)\n",
    "    state = Input(shape=state_shape_flattened)\n",
    "    x = Dense(units[0], name=\"L0\", activation=\"relu\")(state)\n",
    "    for index in range(1, len(units)):\n",
    "        x = Dense(units[index], name=\"L{}\".format(index), activation=\"relu\")(x)\n",
    "\n",
    "    actions_mean = Dense(action_shape[0], name=\"Out_mean\")(x)\n",
    "    actions_std = Dense(action_shape[0], name=\"Out_std\")(x)\n",
    "\n",
    "    model = Model(inputs=state, outputs=[actions_mean, actions_std], name=\"Actor\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def critic(state_shape, action_shape, units=(512, 256, 64)):\n",
    "    state_shape_flattened = functools.reduce(lambda x, y: x * y, state_shape)\n",
    "    inputs = [Input(shape=state_shape_flattened), Input(shape=action_shape)]\n",
    "    concat = Concatenate(axis=-1)(inputs)\n",
    "    x = Dense(units[0], name=\"Hidden0\", activation=\"relu\")(concat)\n",
    "    for index in range(1, len(units)):\n",
    "        x = Dense(units[index], name=\"Hidden{}\".format(index), activation=\"relu\")(x)\n",
    "\n",
    "    output = Dense(1, name=\"Out_QVal\")(x)\n",
    "    model = Model(inputs=inputs, outputs=output, name=\"Critic\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_target_weights(model, target_model, tau=0.005):\n",
    "    weights = model.get_weights()\n",
    "    target_weights = target_model.get_weights()\n",
    "    for i in range(len(target_weights)):  # set tau% of target model to be new weights\n",
    "        target_weights[i] = weights[i] * tau + target_weights[i] * (1 - tau)\n",
    "    target_model.set_weights(target_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAC(object):\n",
    "    def __init__(\n",
    "        self,\n",
    "        env,\n",
    "        lr_actor=3e-5,\n",
    "        lr_critic=3e-4,\n",
    "        actor_units=(64, 64),\n",
    "        critic_units=(64, 64),\n",
    "        auto_alpha=True,\n",
    "        alpha=0.2,\n",
    "        tau=0.005,\n",
    "        gamma=0.99,\n",
    "        batch_size=128,\n",
    "        memory_cap=100000,\n",
    "    ):\n",
    "        self.env = env\n",
    "        self.state_shape = env.observation_space.shape  # shape of observations\n",
    "        self.action_shape = env.action_space.shape  # number of actions\n",
    "        self.action_bound = (env.action_space.high - env.action_space.low) / 2\n",
    "        self.action_shift = (env.action_space.high + env.action_space.low) / 2\n",
    "        self.memory = deque(maxlen=int(memory_cap))\n",
    "\n",
    "        # Define and initialize actor network\n",
    "        self.actor = actor(self.state_shape, self.action_shape, actor_units)\n",
    "        self.actor_optimizer = Adam(learning_rate=lr_actor)\n",
    "        self.log_std_min = -20\n",
    "        self.log_std_max = 2\n",
    "        print(self.actor.summary())\n",
    "\n",
    "        # Define and initialize critic networks\n",
    "        self.critic_1 = critic(self.state_shape, self.action_shape, critic_units)\n",
    "        self.critic_target_1 = critic(self.state_shape, self.action_shape, critic_units)\n",
    "        self.critic_optimizer_1 = Adam(learning_rate=lr_critic)\n",
    "        update_target_weights(self.critic_1, self.critic_target_1, tau=1.0)\n",
    "\n",
    "        self.critic_2 = critic(self.state_shape, self.action_shape, critic_units)\n",
    "        self.critic_target_2 = critic(self.state_shape, self.action_shape, critic_units)\n",
    "        self.critic_optimizer_2 = Adam(learning_rate=lr_critic)\n",
    "        update_target_weights(self.critic_2, self.critic_target_2, tau=1.0)\n",
    "\n",
    "        print(self.critic_1.summary())\n",
    "\n",
    "        # Define and initialize temperature alpha and target entropy\n",
    "        self.auto_alpha = auto_alpha\n",
    "        if auto_alpha:\n",
    "            self.target_entropy = -np.prod(self.action_shape)\n",
    "            self.log_alpha = tf.Variable(0.0, dtype=tf.float64)\n",
    "            self.alpha = tf.Variable(0.0, dtype=tf.float64)\n",
    "            self.alpha.assign(tf.exp(self.log_alpha))\n",
    "            self.alpha_optimizer = Adam(learning_rate=lr_actor)\n",
    "        else:\n",
    "            self.alpha = tf.Variable(alpha, dtype=tf.float64)\n",
    "\n",
    "        # Set hyperparameters\n",
    "        self.gamma = gamma  # discount factor\n",
    "        self.tau = tau  # target model update\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        # Tensorboard\n",
    "        self.summaries = {}\n",
    "\n",
    "    def process_actions(self, mean, log_std, test=False, eps=1e-6):\n",
    "        std = tf.math.exp(log_std)\n",
    "        raw_actions = mean\n",
    "\n",
    "        if not test:\n",
    "            raw_actions += tf.random.normal(shape=mean.shape, dtype=tf.float64) * std\n",
    "\n",
    "        log_prob_u = tfp.distributions.Normal(loc=mean, scale=std).log_prob(raw_actions)\n",
    "        actions = tf.math.tanh(raw_actions)\n",
    "\n",
    "        log_prob = tf.reduce_sum(log_prob_u - tf.math.log(1 - actions ** 2 + eps))\n",
    "\n",
    "        actions = actions * self.action_bound + self.action_shift\n",
    "\n",
    "        return actions, log_prob\n",
    "\n",
    "    def act(self, state, test=False, use_random=False):\n",
    "        state = state.reshape(-1)  # Flatten state\n",
    "        state = np.expand_dims(state, axis=0).astype(np.float64)\n",
    "\n",
    "        if use_random:\n",
    "            a = tf.random.uniform(\n",
    "                shape=(1, self.action_shape[0]), minval=-1, maxval=1, dtype=tf.float64\n",
    "            )\n",
    "        else:\n",
    "            means, log_stds = self.actor.predict(state)\n",
    "            log_stds = tf.clip_by_value(log_stds, self.log_std_min, self.log_std_max)\n",
    "\n",
    "            a, log_prob = self.process_actions(means, log_stds, test=test)\n",
    "\n",
    "        q1 = self.critic_1.predict([state, a])[0][0]\n",
    "        q2 = self.critic_2.predict([state, a])[0][0]\n",
    "        self.summaries[\"q_min\"] = tf.math.minimum(q1, q2)\n",
    "        self.summaries[\"q_mean\"] = np.mean([q1, q2])\n",
    "\n",
    "        return a\n",
    "\n",
    "    def save_model(self, a_fn, c_fn):\n",
    "        self.actor.save(a_fn)\n",
    "        self.critic_1.save(c_fn)\n",
    "\n",
    "    def load_actor(self, a_fn):\n",
    "        self.actor.load_weights(a_fn)\n",
    "        print(self.actor.summary())\n",
    "\n",
    "    def load_critic(self, c_fn):\n",
    "        self.critic_1.load_weights(c_fn)\n",
    "        self.critic_target_1.load_weights(c_fn)\n",
    "        self.critic_2.load_weights(c_fn)\n",
    "        self.critic_target_2.load_weights(c_fn)\n",
    "        print(self.critic_1.summary())\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        state = state.reshape(-1)  # Flatten state\n",
    "        state = np.expand_dims(state, axis=0)\n",
    "        next_state = next_state.reshape(-1)  # Flatten next-state\n",
    "        next_state = np.expand_dims(next_state, axis=0)\n",
    "        self.memory.append([state, action, reward, next_state, done])\n",
    "\n",
    "    def replay(self):\n",
    "        if len(self.memory) < self.batch_size:\n",
    "            return\n",
    "\n",
    "        samples = random.sample(self.memory, self.batch_size)\n",
    "        s = np.array(samples).T\n",
    "        states, actions, rewards, next_states, dones = [\n",
    "            np.vstack(s[i, :]).astype(np.float) for i in range(5)\n",
    "        ]\n",
    "\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            # next state action log probs\n",
    "            means, log_stds = self.actor(next_states)\n",
    "            log_stds = tf.clip_by_value(log_stds, self.log_std_min, self.log_std_max)\n",
    "            next_actions, log_probs = self.process_actions(means, log_stds)\n",
    "\n",
    "            # critics loss\n",
    "            current_q_1 = self.critic_1([states, actions])\n",
    "            current_q_2 = self.critic_2([states, actions])\n",
    "            next_q_1 = self.critic_target_1([next_states, next_actions])\n",
    "            next_q_2 = self.critic_target_2([next_states, next_actions])\n",
    "            next_q_min = tf.math.minimum(next_q_1, next_q_2)\n",
    "            state_values = next_q_min - self.alpha * log_probs\n",
    "            target_qs = tf.stop_gradient(\n",
    "                rewards + state_values * self.gamma * (1.0 - dones)\n",
    "            )\n",
    "            critic_loss_1 = tf.reduce_mean(\n",
    "                0.5 * tf.math.square(current_q_1 - target_qs)\n",
    "            )\n",
    "            critic_loss_2 = tf.reduce_mean(\n",
    "                0.5 * tf.math.square(current_q_2 - target_qs)\n",
    "            )\n",
    "\n",
    "            # current state action log probs\n",
    "            means, log_stds = self.actor(states)\n",
    "            log_stds = tf.clip_by_value(log_stds, self.log_std_min, self.log_std_max)\n",
    "            actions, log_probs = self.process_actions(means, log_stds)\n",
    "\n",
    "            # actor loss\n",
    "            current_q_1 = self.critic_1([states, actions])\n",
    "            current_q_2 = self.critic_2([states, actions])\n",
    "            current_q_min = tf.math.minimum(current_q_1, current_q_2)\n",
    "            actor_loss = tf.reduce_mean(self.alpha * log_probs - current_q_min)\n",
    "\n",
    "            # temperature loss\n",
    "            if self.auto_alpha:\n",
    "                alpha_loss = -tf.reduce_mean(\n",
    "                    (self.log_alpha * tf.stop_gradient(log_probs + self.target_entropy))\n",
    "                )\n",
    "\n",
    "        critic_grad = tape.gradient(\n",
    "            critic_loss_1, self.critic_1.trainable_variables\n",
    "        )  # compute actor gradient\n",
    "        self.critic_optimizer_1.apply_gradients(\n",
    "            zip(critic_grad, self.critic_1.trainable_variables)\n",
    "        )\n",
    "\n",
    "        critic_grad = tape.gradient(\n",
    "            critic_loss_2, self.critic_2.trainable_variables\n",
    "        )  # compute actor gradient\n",
    "        self.critic_optimizer_2.apply_gradients(\n",
    "            zip(critic_grad, self.critic_2.trainable_variables)\n",
    "        )\n",
    "\n",
    "        actor_grad = tape.gradient(\n",
    "            actor_loss, self.actor.trainable_variables\n",
    "        )  # compute actor gradient\n",
    "        self.actor_optimizer.apply_gradients(\n",
    "            zip(actor_grad, self.actor.trainable_variables)\n",
    "        )\n",
    "\n",
    "        # tensorboard info\n",
    "        self.summaries[\"q1_loss\"] = critic_loss_1\n",
    "        self.summaries[\"q2_loss\"] = critic_loss_2\n",
    "        self.summaries[\"actor_loss\"] = actor_loss\n",
    "\n",
    "        if self.auto_alpha:\n",
    "            # optimize temperature\n",
    "            alpha_grad = tape.gradient(alpha_loss, [self.log_alpha])\n",
    "            self.alpha_optimizer.apply_gradients(zip(alpha_grad, [self.log_alpha]))\n",
    "            self.alpha.assign(tf.exp(self.log_alpha))\n",
    "            # tensorboard info\n",
    "            self.summaries[\"alpha_loss\"] = alpha_loss\n",
    "\n",
    "    def train(self, max_epochs=8000, random_epochs=1000, max_steps=1000, save_freq=50):\n",
    "        current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        train_log_dir = os.path.join(\"logs\", \"TFRL-Cookbook-Ch4-SAC\", current_time)\n",
    "        summary_writer = tf.summary.create_file_writer(train_log_dir)\n",
    "\n",
    "        done, use_random, episode, steps, epoch, episode_reward = (\n",
    "            False,\n",
    "            True,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "        )\n",
    "        cur_state = self.env.reset()\n",
    "\n",
    "        while epoch < max_epochs:\n",
    "            if steps > max_steps:\n",
    "                done = True\n",
    "\n",
    "            if done:\n",
    "                episode += 1\n",
    "                print(\n",
    "                    \"episode {}: {} total reward, {} alpha, {} steps, {} epochs\".format(\n",
    "                        episode, episode_reward, self.alpha.numpy(), steps, epoch\n",
    "                    )\n",
    "                )\n",
    "\n",
    "                with summary_writer.as_default():\n",
    "                    tf.summary.scalar(\n",
    "                        \"Main/episode_reward\", episode_reward, step=episode\n",
    "                    )\n",
    "                    tf.summary.scalar(\"Main/episode_steps\", steps, step=episode)\n",
    "\n",
    "                summary_writer.flush()\n",
    "\n",
    "                done, cur_state, steps, episode_reward = False, self.env.reset(), 0, 0\n",
    "                if episode % save_freq == 0:\n",
    "                    self.save_model(\n",
    "                        \"sac_actor_episode{}.h5\".format(episode),\n",
    "                        \"sac_critic_episode{}.h5\".format(episode),\n",
    "                    )\n",
    "\n",
    "            if epoch > random_epochs and len(self.memory) > self.batch_size:\n",
    "                use_random = False\n",
    "\n",
    "            action = self.act(cur_state, use_random=use_random)  # determine action\n",
    "            next_state, reward, done, _ = self.env.step(action[0])  # act on env\n",
    "            # self.env.render(mode='rgb_array')\n",
    "\n",
    "            self.remember(cur_state, action, reward, next_state, done)  # add to memory\n",
    "            self.replay()  # train models through memory replay\n",
    "\n",
    "            update_target_weights(\n",
    "                self.critic_1, self.critic_target_1, tau=self.tau\n",
    "            )  # iterates target model\n",
    "            update_target_weights(self.critic_2, self.critic_target_2, tau=self.tau)\n",
    "\n",
    "            cur_state = next_state\n",
    "            episode_reward += reward\n",
    "            steps += 1\n",
    "            epoch += 1\n",
    "\n",
    "            # Tensorboard update\n",
    "            with summary_writer.as_default():\n",
    "                if len(self.memory) > self.batch_size:\n",
    "                    tf.summary.scalar(\n",
    "                        \"Loss/actor_loss\", self.summaries[\"actor_loss\"], step=epoch\n",
    "                    )\n",
    "                    tf.summary.scalar(\n",
    "                        \"Loss/q1_loss\", self.summaries[\"q1_loss\"], step=epoch\n",
    "                    )\n",
    "                    tf.summary.scalar(\n",
    "                        \"Loss/q2_loss\", self.summaries[\"q2_loss\"], step=epoch\n",
    "                    )\n",
    "                    if self.auto_alpha:\n",
    "                        tf.summary.scalar(\n",
    "                            \"Loss/alpha_loss\", self.summaries[\"alpha_loss\"], step=epoch\n",
    "                        )\n",
    "\n",
    "                tf.summary.scalar(\"Stats/alpha\", self.alpha, step=epoch)\n",
    "                if self.auto_alpha:\n",
    "                    tf.summary.scalar(\"Stats/log_alpha\", self.log_alpha, step=epoch)\n",
    "                tf.summary.scalar(\"Stats/q_min\", self.summaries[\"q_min\"], step=epoch)\n",
    "                tf.summary.scalar(\"Stats/q_mean\", self.summaries[\"q_mean\"], step=epoch)\n",
    "                tf.summary.scalar(\"Main/step_reward\", reward, step=epoch)\n",
    "\n",
    "            summary_writer.flush()\n",
    "\n",
    "        self.save_model(\n",
    "            \"sac_actor_final_episode{}.h5\".format(episode),\n",
    "            \"sac_critic_final_episode{}.h5\".format(episode),\n",
    "        )\n",
    "\n",
    "    def test(self, render=True, fps=30, filename=\"test_render.mp4\"):\n",
    "        cur_state, done, rewards = self.env.reset(), False, 0\n",
    "        video = imageio.get_writer(filename, fps=fps)\n",
    "        while not done:\n",
    "            action = self.act(cur_state, test=True)\n",
    "            next_state, reward, done, _ = self.env.step(action[0])\n",
    "            cur_state = next_state\n",
    "            rewards += reward\n",
    "            if render:\n",
    "                video.append_data(self.env.render(mode=\"rgb_array\"))\n",
    "        video.close()\n",
    "        return rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/runner/miniconda/envs/tfrl-cookbook/lib/python3.8/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float64\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Actor\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 186)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "L0 (Dense)                      (None, 64)           11968       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "L1 (Dense)                      (None, 64)           4160        L0[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "Out_mean (Dense)                (None, 1)            65          L1[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "Out_std (Dense)                 (None, 1)            65          L1[0][0]                         \n",
      "==================================================================================================\n",
      "Total params: 16,258\n",
      "Trainable params: 16,258\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Model: \"Critic\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 186)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 187)          0           input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Hidden0 (Dense)                 (None, 64)           12032       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Hidden1 (Dense)                 (None, 64)           4160        Hidden0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Out_QVal (Dense)                (None, 1)            65          Hidden1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 16,257\n",
      "Trainable params: 16,257\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    gym_env = StockTradingContinuousEnv()\n",
    "    sac = SAC(gym_env)\n",
    "\n",
    "    # sac.load_actor(\"sac_actor_episodexyz.h5\")\n",
    "    # sac.load_critic(\"sac_critic_episodexyz.h5\")\n",
    "\n",
    "    sac.train(max_epochs=3, random_epochs=1, save_freq=2)\n",
    "    # Comment above line, uncomment the below line for reasonable training\n",
    "    # sac.train(max_epochs=100000, random_epochs=10000, save_freq=50)\n",
    "\n",
    "    # reward = sac.test()\n",
    "    # print(reward)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "executable": "/usr/bin/env python",
   "formats": "ipynb,py"
  },
  "kernelspec": {
   "display_name": "tfrl-cookbook",
   "language": "python",
   "name": "tfrl-cookbook"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
