## $5 Tech Unlocked 2021!
[Buy and download this product for only $5 on PacktPub.com](https://www.packtpub.com/)
-----
*The $5 campaign         runs from __December 15th 2020__ to __January 13th 2021.__*

# TensorFlow 2 Reinforcement Learning Cookbook

## About the TFRL Cookbook

The TFRL Cookbook provides recipes for you to:
| |
| :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| **Build**: Deep RL agents from scratch using the all-new and powerful TensorFlow 2.x framework and Keras API |
| **Implement**: Deep RL algorithms (DQN, A3C, DDPG, PPO, SAC etc.) with minimal lines of code |
| **Train**: Deep RL agents in simulated environments (gyms) beyond toy-problems and games to perform real-world tasks like cryptocurrency trading, stock trading, tweet/email management and more! |
| **Scale**: Distributed training of RL agents using TensorFlow 2.x, Ray + Tune + RLLib |
| **Deploy**: RL agents to the cloud and edge for real-world testing by creating cloud services, web apps and Android mobile apps using TensorFlow Lite, TensorFlow.js, ONNX and Triton |
| |

## TFRL Cookbook recipes

### Chapter 1: Developing building blocks for Deep RL using TensorFlow 2.x & Keras

- 1.1 Building environment and reward mechanism for training RL agents

- 1.2 Implementing neural-network-based RL policies for discrete action spaces and decision-making problems

- 1.3 Implementing neural-network-based RL policies for continuous action spaces and continuous-control problems

- 1.4 Working with OpenAI Gym for RL training environments

- 1.5 Building a neural agent

- 1.6 Building a neural evolutionary Agent

### Chapter 2: Implementing value-based, policy gradients and actor-critic Deep RL algorithms

- 2.1 Building stochastic environmnts for training RL agents

- 2.2 Building value-based Reinforcement Learning agent algorithms

- 2.3 Implementing Temporal Difference (TD) Learning

- 2.4 Building Monte-Carlo prediction and control for RL

- 2.5 Implementing SARSA algorithm and SARSA agent

- 2.6 Building a Q-Learning agent

- 2.7 Implementing Policy Gradients (PG) and a PG agent

- 2.8 Implementing Actor-Critic Algorithms and agent

### Chapter 3: Implementing Advanced (Deep) RL algorithms

- 3.1 Implementing Deep Q-Learning, DQN and Double-DQN agent

- 3.2 Implementing Dueling DQN agent

- 3.3 Implementing Double Dueling DQN algorithm and the DDDQN agent

- 3.4 Implementing Deep Recurrent Q-Learning algorithm and the DRQN Agent

- 3.5 Implementing Asynchronous Advantage Actor-Critic algorithm and the A3C agent

- 3.6 Implementing Proximal Policy Optimization algorithm and the PPO agent

- 3.7 Implementing Deep Deterministic Policy Gradient algorithm and the DDPG agent

### Chapter 4: RL in real-world: Building cryptocurrency trading agents

- 4.1 Building Bitcoin trading RL platform using real market data

- 4.2 Building Ethereum tradingRL platform using price charts

- 4.3 Building advanced cryptocurrency trading platform for RL agents

- 4.4 Training cryptocurrency trading bot using RL

### Chapter 5: RL in real-world: Building stock/share trading agents

- 5.1 Building stock-market trading RL platform using real stock-exchange data

- 5.2 Building stock-market trading RL platform using price charts

- 5.3 Building advanced stock trading RL platform to train agents that trade like human pros

### Chapter 6: RL in real-world: Building intelligent agents to complete your To-Dos

- 6.1 Building learning environments for real-world RL

- 6.2 Building an RL agent to complete tasks on the web: Call to Action bot

- 6.3 Building a visual auto-login bot

- 6.4 Training an RL agent to automate flight booking for your travel

- 6.5 Training an RL agent to manage your emails

- 6.6 Training an RL agent to automate your social-media account management

### Chapter 7: Deploying Deep RL agents to the cloud

- 7.1 Implementing RL agent's runtime components

- 7.2 Building RL environment simulator as a service

- 7.3 Training RL agents using remote simulator instances

- 7.4 Ealuating/testing RL agents

- 7.5 Packaging RL agents for deployment: A trading bot

- 7.6 Deploying RL agents to the cloud: Trading-Bot-as-a-Service

### Chapter 8: Distributed training for accelerated development of Deep RL agents

- 8.1 Building distributed deep learning models using TensorFlow 2.x: Multi-GPU training

- 8.2 Scaling up and out: Multi-machine, multi-GPU training

- 8.3 Training Deep RL agents at scale: Multi-GPU PPO agent

- 8.4 Building blocks for distributed Deep Reinforcement learning for accelerated training

- 8.5 Large-scale Deep RL agent training using Ray, Tune and RLLib

### Chapter 9: Deploying Deep RL agents on multiple platforms

- 9.0 Runtime options for cross-platform deployments

- 9.1 Packaging Deep RL agents for mobile and IoT devices using TensorFlow Lite

- 9.2 Deploying RL agents on mobile devices

- 9.3 Packaging Deep RL agents for the web and Node.js using TensorFlow.js

- 9.4 Deploying Deep-RL-Agent-as-a-Service

- 9.5 Packaging Deep RL agents for cross-platform deployments

## Getting started

1. Install system dependencies:`sudo apt install -y make cmake ffmpeg`
2. Install miniconda: `wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh && bash -b -p ${HOME}/miniconda3`
3. Setup conda python virtual environment: `bash && conda env create -f tfrl-cookbook.yml -n "tfrl-cookbook"`
   You are all set!

4. Activate the `tfrl-cookbook` conda python environment: `conda activate tfrl-cookbook` and get started with the recipes in the book!
