{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Evolutionary Agent for GridWorld RL environment with image observations\n",
    "Chapter 1, TensorFlow 2 Reinforcement Learning Cookbook | Praveen Palanisamy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import envs  # Required to register Gridworld-v0 env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Brain(keras.Model):\n",
    "    def __init__(self, action_dim=5, input_shape=(1, 8 * 8)):\n",
    "        \"\"\"Initialize the Agent's Brain model\n",
    "\n",
    "        Args:\n",
    "            action_dim (int): Number of actions\n",
    "        \"\"\"\n",
    "        super(Brain, self).__init__()\n",
    "        self.dense1 = layers.Dense(32, input_shape=input_shape, activation=\"relu\")\n",
    "        self.logits = layers.Dense(action_dim)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = tf.convert_to_tensor(inputs)\n",
    "        logits = self.logits(self.dense1(x))\n",
    "        return logits\n",
    "\n",
    "    def process(self, observations):\n",
    "        # Process batch observations using `call(inputs)` behind-the-scenes\n",
    "        action_logits = self.predict_on_batch(observations)\n",
    "        return action_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent(object):\n",
    "    def __init__(self, action_dim=5, input_shape=(1, 8 * 8)):\n",
    "        \"\"\"Agent with a neural-network brain powered policy\n",
    "\n",
    "        Args:\n",
    "            brain (keras.Model): Neural Network based model\n",
    "        \"\"\"\n",
    "        self.brain = Brain(action_dim, input_shape)\n",
    "        self.brain.compile(\n",
    "            loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]\n",
    "        )\n",
    "        self.policy = self.policy_mlp\n",
    "\n",
    "    def policy_mlp(self, observations):\n",
    "        observations = observations.reshape(1, -1)\n",
    "        action_logits = self.brain.process(observations)\n",
    "        action = tf.random.categorical(tf.math.log(action_logits), num_samples=1)\n",
    "        return action  # tf.squeeze(action, axis=0)\n",
    "\n",
    "    def get_action(self, observations):\n",
    "        return self.policy(observations)\n",
    "\n",
    "    def learn(self, obs, actions, **kwargs):\n",
    "        self.brain.fit(obs, actions, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Trajectory = namedtuple(\"Trajectory\", [\"obs\", \"actions\", \"reward\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate agent in the given environment\n",
    "def evaluate(agent, env, render=True):\n",
    "    obs, episode_reward, done, step_num, info = env.reset(), 0.0, False, 0, None\n",
    "    while not done:\n",
    "        action = agent.get_action(obs)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        episode_reward += reward\n",
    "        step_num += 1\n",
    "        if render:\n",
    "            env.render()\n",
    "    return step_num, episode_reward, done, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rollout(agent, env, render=False):\n",
    "    \"\"\"Rollout `agent` in the `environment` for 1 episode\n",
    "    Args:\n",
    "        agent (Agent): Agent/policy to generate state-conditioned actions\n",
    "        env (gym.Env): A Gym environment\n",
    "        total_steps (int, optional): Totall number of steps to rollout. Defaults to 1000.\n",
    "        render (bool, optional): Enable/disable rendering. Defaults to False.\n",
    "    Returns:\n",
    "        obs_batch (List): Batch of observations collected in the episode\n",
    "        actions_batch (List): Batch of actions performed in the episode\n",
    "        episode_reward (float): Total rewards accumulated in this episode\n",
    "    \"\"\"\n",
    "    obs, episode_reward, done, step_num = env.reset(), 0.0, False, 0\n",
    "    observations, actions = [], []\n",
    "    episode_reward = 0.0\n",
    "    while not done:\n",
    "        action = agent.get_action(obs)\n",
    "        next_obs, reward, done, info = env.step(action)\n",
    "        # Save experience\n",
    "        observations.append(\n",
    "            np.array(obs).reshape(-1)\n",
    "        )  # Convert to numpy & reshape (8, 8) to (1, 64)\n",
    "        actions.append(np.squeeze(action, 0))\n",
    "        episode_reward += reward\n",
    "\n",
    "        obs = next_obs\n",
    "        step_num += 1\n",
    "        if render:\n",
    "            env.render()\n",
    "    env.close()\n",
    "    return observations, actions, episode_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_elite_xp(trajectories, elitism_criterion):\n",
    "    \"\"\"Gather elite trajectories from the batch of trajectories\n",
    "    Args:\n",
    "        batch_trajectories (List): List of episode trajectories containing experiences (obs, actions, episode_reward)\n",
    "    Returns:\n",
    "        elite_batch_obs\n",
    "        elite_batch_actions\n",
    "        elite_reard_threshold\n",
    "    \"\"\"\n",
    "    trajectory_obs, trajectory_actions, trajectory_rewards = zip(*trajectories)\n",
    "    reward_threshold = np.percentile(trajectory_rewards, elitism_criterion)\n",
    "    indices = [\n",
    "        index\n",
    "        for index, value in enumerate(trajectory_rewards)\n",
    "        if value >= reward_threshold\n",
    "    ]\n",
    "\n",
    "    elite_trajectory_obs = [trajectory_obs[i] for i in indices]\n",
    "    elite_trajectory_actions = [trajectory_actions[i] for i in indices]\n",
    "    unpacked_elite_batch_obs = [\n",
    "        item for items in elite_trajectory_obs for item in items\n",
    "    ]\n",
    "    unpacked_elite_batch_actions = [\n",
    "        item for items in elite_trajectory_actions for item in items\n",
    "    ]\n",
    "    return (\n",
    "        np.array(unpacked_elite_batch_obs),\n",
    "        np.array(unpacked_elite_batch_actions),\n",
    "        reward_threshold,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_action_distribution(action_index, action_dim=5):\n",
    "    action_distribution = np.zeros(action_dim).astype(type(action_index))\n",
    "    action_distribution[action_index] = 1\n",
    "    # action_distribution = np.expand_dims(action_distribution, 0)\n",
    "    return action_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    env_id=\"Gridworld-v0\",\n",
    "    num_trajectory_rollouts=70,\n",
    "    elitism_criterion=70,\n",
    "    num_epochs=10,\n",
    "):\n",
    "    \"\"\"Train Agent in the given Gym `env` using approximate Cross-Entropy\n",
    "\n",
    "    Args:\n",
    "        env (str, optional): Name of the Gym environment. Defaults to \"Gridworld-v0\".\n",
    "        num_trajectory_rollouts (int, optional): Number of trajectories to rollouts/sample. Defaults to 70.\n",
    "        elitism_criterion (int, optional): Threshold (as a percentage) to choose elites. Defaults to 70.\n",
    "        num_epochs (int, optional): Number of epochs to train on the elite trajectories. Defaults to 10.\n",
    "    \"\"\"\n",
    "    num_trajectory_rollouts = num_trajectory_rollouts\n",
    "    elitism_criterion = elitism_criterion  # Percentage\n",
    "    num_epochs = num_epochs\n",
    "\n",
    "    env = gym.make(env_id)\n",
    "    agent = Agent(env.action_space.n, env.observation_space.shape)\n",
    "\n",
    "    mean_rewards = []\n",
    "    elite_reward_thresholds = []\n",
    "    for i in tqdm(range(num_epochs)):\n",
    "        trajectories = [\n",
    "            Trajectory(*rollout(agent, env)) for _ in range(num_trajectory_rollouts)\n",
    "        ]\n",
    "        _, _, batch_rewards = zip(*trajectories)\n",
    "        elite_obs, elite_actions, elite_threshold = gather_elite_xp(\n",
    "            trajectories, elitism_criterion=elitism_criterion\n",
    "        )\n",
    "        elite_action_distributions = np.array(\n",
    "            [gen_action_distribution(a.item()) for a in elite_actions]\n",
    "        )\n",
    "        elite_obs, elite_action_distributions = (\n",
    "            elite_obs.astype(\"float16\"),\n",
    "            elite_action_distributions.astype(\"float16\"),\n",
    "        )\n",
    "        agent.learn(\n",
    "            elite_obs, elite_action_distributions, batch_size=128, epochs=3, verbose=0\n",
    "        )\n",
    "        mean_rewards.append(np.mean(batch_rewards))\n",
    "        elite_reward_thresholds.append(elite_threshold)\n",
    "        print(\n",
    "            f\"Episode#:{i + 1} elite-reward-threshold:{elite_reward_thresholds[-1]:.2f} reward:{mean_rewards[-1]:.2f} \"\n",
    "        )\n",
    "\n",
    "    plt.plot(mean_rewards, \"r-\", label=\"mean_reward\")\n",
    "    plt.plot(elite_reward_thresholds, \"g--\", label=\"elites_reward_threshold\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 1/2 [00:18<00:18, 18.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode#:1 elite-reward-threshold:-9.50 reward:-9.50 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 2/2 [00:35<00:00, 17.98s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 2/2 [00:35<00:00, 17.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode#:2 elite-reward-threshold:-9.50 reward:-9.50 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    train(num_epochs=2)  # Increase value of num_epochs"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "executable": "/usr/bin/env python",
   "formats": "ipynb,py"
  },
  "kernelspec": {
   "display_name": "tfrl-cookbook",
   "language": "python",
   "name": "tfrl-cookbook"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
