{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Evolutionary Agent for GridWorld RL environment with image observations\n",
    "Chapter 1, TensorFlow 2 Reinforcement Learning Cookbook | Praveen Palanisamy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import envs  # Required to register Gridworld-v0 env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Brain(keras.Model):\n",
    "    def __init__(self, action_dim=5, input_shape=(1, 8 * 8)):\n",
    "        \"\"\"Initialize the Agent's Brain model\n",
    "\n",
    "        Args:\n",
    "            action_dim (int): Number of actions\n",
    "        \"\"\"\n",
    "        super(Brain, self).__init__()\n",
    "        self.dense1 = layers.Dense(32, input_shape=input_shape, activation=\"relu\")\n",
    "        self.logits = layers.Dense(action_dim)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = tf.convert_to_tensor(inputs)\n",
    "        logits = self.logits(self.dense1(x))\n",
    "        return logits\n",
    "\n",
    "    def process(self, observations):\n",
    "        # Process batch observations using `call(inputs)` behind-the-scenes\n",
    "        action_logits = self.predict_on_batch(observations)\n",
    "        return action_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent(object):\n",
    "    def __init__(self, action_dim=5, input_shape=(1, 8 * 8)):\n",
    "        \"\"\"Agent with a neural-network brain powered policy\n",
    "\n",
    "        Args:\n",
    "            brain (keras.Model): Neural Network based model\n",
    "        \"\"\"\n",
    "        self.brain = Brain(action_dim, input_shape)\n",
    "        self.brain.compile(\n",
    "            loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]\n",
    "        )\n",
    "        self.policy = self.policy_mlp\n",
    "\n",
    "    def policy_mlp(self, observations):\n",
    "        observations = observations.reshape(1, -1)\n",
    "        action_logits = self.brain.process(observations)\n",
    "        action = tf.random.categorical(tf.math.log(action_logits), num_samples=1)\n",
    "        return action  # tf.squeeze(action, axis=0)\n",
    "\n",
    "    def get_action(self, observations):\n",
    "        return self.policy(observations)\n",
    "\n",
    "    def learn(self, obs, actions, **kwargs):\n",
    "        self.brain.fit(obs, actions, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Trajectory = namedtuple(\"Trajectory\", [\"obs\", \"actions\", \"reward\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate agent in the given environment\n",
    "def evaluate(agent, env, render=True):\n",
    "    obs, episode_reward, done, step_num, info = env.reset(), 0.0, False, 0, None\n",
    "    while not done:\n",
    "        action = agent.get_action(obs)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        episode_reward += reward\n",
    "        step_num += 1\n",
    "        if render:\n",
    "            env.render()\n",
    "    return step_num, episode_reward, done, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rollout(agent, env, render=False):\n",
    "    \"\"\"Rollout `agent` in the `environment` for 1 episode\n",
    "    Args:\n",
    "        agent (Agent): Agent/policy to generate state-conditioned actions\n",
    "        env (gym.Env): A Gym environment\n",
    "        total_steps (int, optional): Totall number of steps to rollout. Defaults to 1000.\n",
    "        render (bool, optional): Enable/disable rendering. Defaults to False.\n",
    "    Returns:\n",
    "        obs_batch (List): Batch of observations collected in the episode\n",
    "        actions_batch (List): Batch of actions performed in the episode\n",
    "        episode_reward (float): Total rewards accumulated in this episode\n",
    "    \"\"\"\n",
    "    obs, episode_reward, done, step_num = env.reset(), 0.0, False, 0\n",
    "    observations, actions = [], []\n",
    "    episode_reward = 0.0\n",
    "    while not done:\n",
    "        action = agent.get_action(obs)\n",
    "        next_obs, reward, done, info = env.step(action)\n",
    "        # Save experience\n",
    "        observations.append(\n",
    "            np.array(obs).reshape(-1)\n",
    "        )  # Convert to numpy & reshape (8, 8) to (1, 64)\n",
    "        actions.append(np.squeeze(action, 0))\n",
    "        episode_reward += reward\n",
    "\n",
    "        obs = next_obs\n",
    "        step_num += 1\n",
    "        if render:\n",
    "            env.render()\n",
    "    env.close()\n",
    "    return observations, actions, episode_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_elite_xp(trajectories, elitism_criterion):\n",
    "    \"\"\"Gather elite trajectories from the batch of trajectories\n",
    "    Args:\n",
    "        batch_trajectories (List): List of episode trajectories containing experiences (obs, actions, episode_reward)\n",
    "    Returns:\n",
    "        elite_batch_obs\n",
    "        elite_batch_actions\n",
    "        elite_reard_threshold\n",
    "    \"\"\"\n",
    "    trajectory_obs, trajectory_actions, trajectory_rewards = zip(*trajectories)\n",
    "    reward_threshold = np.percentile(trajectory_rewards, elitism_criterion)\n",
    "    indices = [\n",
    "        index\n",
    "        for index, value in enumerate(trajectory_rewards)\n",
    "        if value >= reward_threshold\n",
    "    ]\n",
    "\n",
    "    elite_trajectory_obs = [trajectory_obs[i] for i in indices]\n",
    "    elite_trajectory_actions = [trajectory_actions[i] for i in indices]\n",
    "    unpacked_elite_batch_obs = [\n",
    "        item for items in elite_trajectory_obs for item in items\n",
    "    ]\n",
    "    unpacked_elite_batch_actions = [\n",
    "        item for items in elite_trajectory_actions for item in items\n",
    "    ]\n",
    "    return (\n",
    "        np.array(unpacked_elite_batch_obs),\n",
    "        np.array(unpacked_elite_batch_actions),\n",
    "        reward_threshold,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_action_distribution(action_index, action_dim=5):\n",
    "    action_distribution = np.zeros(action_dim).astype(type(action_index))\n",
    "    action_distribution[action_index] = 1\n",
    "    # action_distribution = np.expand_dims(action_distribution, 0)\n",
    "    return action_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    env_id=\"Gridworld-v0\",\n",
    "    num_trajectory_rollouts=70,\n",
    "    elitism_criterion=70,\n",
    "    num_epochs=10,\n",
    "):\n",
    "    \"\"\"Train Agent in the given Gym `env` using approximate Cross-Entropy\n",
    "\n",
    "    Args:\n",
    "        env (str, optional): Name of the Gym environment. Defaults to \"Gridworld-v0\".\n",
    "        num_trajectory_rollouts (int, optional): Number of trajectories to rollouts/sample. Defaults to 70.\n",
    "        elitism_criterion (int, optional): Threshold (as a percentage) to choose elites. Defaults to 70.\n",
    "        num_epochs (int, optional): Number of epochs to train on the elite trajectories. Defaults to 10.\n",
    "    \"\"\"\n",
    "    num_trajectory_rollouts = num_trajectory_rollouts\n",
    "    elitism_criterion = elitism_criterion  # Percentage\n",
    "    num_epochs = num_epochs\n",
    "\n",
    "    env = gym.make(env_id)\n",
    "    agent = Agent(env.action_space.n, env.observation_space.shape)\n",
    "\n",
    "    mean_rewards = []\n",
    "    elite_reward_thresholds = []\n",
    "    for i in tqdm(range(num_epochs)):\n",
    "        trajectories = [\n",
    "            Trajectory(*rollout(agent, env)) for _ in range(num_trajectory_rollouts)\n",
    "        ]\n",
    "        _, _, batch_rewards = zip(*trajectories)\n",
    "        elite_obs, elite_actions, elite_threshold = gather_elite_xp(\n",
    "            trajectories, elitism_criterion=elitism_criterion\n",
    "        )\n",
    "        elite_action_distributions = np.array(\n",
    "            [gen_action_distribution(a.item()) for a in elite_actions]\n",
    "        )\n",
    "        elite_obs, elite_action_distributions = (\n",
    "            elite_obs.astype(\"float16\"),\n",
    "            elite_action_distributions.astype(\"float16\"),\n",
    "        )\n",
    "        agent.learn(\n",
    "            elite_obs, elite_action_distributions, batch_size=128, epochs=3, verbose=0\n",
    "        )\n",
    "        mean_rewards.append(np.mean(batch_rewards))\n",
    "        elite_reward_thresholds.append(elite_threshold)\n",
    "        print(\n",
    "            f\"Episode#:{i + 1} elite-reward-threshold:{elite_reward_thresholds[-1]:.2f} reward:{mean_rewards[-1]:.2f} \"\n",
    "        )\n",
    "\n",
    "    plt.plot(mean_rewards, \"r-\", label=\"mean_reward\")\n",
    "    plt.plot(elite_reward_thresholds, \"g--\", label=\"elites_reward_threshold\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 1/2 [00:19<00:19, 19.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode#:1 elite-reward-threshold:-9.50 reward:-9.59 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 2/2 [00:39<00:00, 19.78s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 2/2 [00:39<00:00, 19.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode#:2 elite-reward-threshold:-9.50 reward:-9.59 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    train(num_epochs=2)  # Increase value of num_epochs"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "executable": "/usr/bin/env python",
   "formats": "ipynb,py"
  },
  "kernelspec": {
   "display_name": "tfrl-cookbook",
   "language": "python",
   "name": "tfrl-cookbook"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
