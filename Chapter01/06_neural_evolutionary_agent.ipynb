{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Evolutionary Agent for GridWorld RL environment with image observations\n",
    "Chapter 1, TensorFlow 2 Reinforcement Learning Cookbook | Praveen Palanisamy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache using fc-list. This may take a moment.\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import envs  # Required to register Gridworld-v0 env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Brain(keras.Model):\n",
    "    def __init__(self, action_dim=5, input_shape=(1, 8 * 8)):\n",
    "        \"\"\"Initialize the Agent's Brain model\n",
    "\n",
    "        Args:\n",
    "            action_dim (int): Number of actions\n",
    "        \"\"\"\n",
    "        super(Brain, self).__init__()\n",
    "        self.dense1 = layers.Dense(32, input_shape=input_shape, activation=\"relu\")\n",
    "        self.logits = layers.Dense(action_dim)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = tf.convert_to_tensor(inputs)\n",
    "        logits = self.logits(self.dense1(x))\n",
    "        return logits\n",
    "\n",
    "    def process(self, observations):\n",
    "        # Process batch observations using `call(inputs)` behind-the-scenes\n",
    "        action_logits = self.predict_on_batch(observations)\n",
    "        return action_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent(object):\n",
    "    def __init__(self, action_dim=5, input_shape=(1, 8 * 8)):\n",
    "        \"\"\"Agent with a neural-network brain powered policy\n",
    "\n",
    "        Args:\n",
    "            brain (keras.Model): Neural Network based model\n",
    "        \"\"\"\n",
    "        self.brain = Brain(action_dim, input_shape)\n",
    "        self.brain.compile(\n",
    "            loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]\n",
    "        )\n",
    "        self.policy = self.policy_mlp\n",
    "\n",
    "    def policy_mlp(self, observations):\n",
    "        observations = observations.reshape(1, -1)\n",
    "        action_logits = self.brain.process(observations)\n",
    "        action = tf.random.categorical(tf.math.log(action_logits), num_samples=1)\n",
    "        return action  # tf.squeeze(action, axis=0)\n",
    "\n",
    "    def get_action(self, observations):\n",
    "        return self.policy(observations)\n",
    "\n",
    "    def learn(self, obs, actions, **kwargs):\n",
    "        self.brain.fit(obs, actions, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Trajectory = namedtuple(\"Trajectory\", [\"obs\", \"actions\", \"reward\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate agent in the given environment\n",
    "def evaluate(agent, env, render=True):\n",
    "    obs, episode_reward, done, step_num, info = env.reset(), 0.0, False, 0, None\n",
    "    while not done:\n",
    "        action = agent.get_action(obs)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        episode_reward += reward\n",
    "        step_num += 1\n",
    "        if render:\n",
    "            env.render()\n",
    "    return step_num, episode_reward, done, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rollout(agent, env, render=False):\n",
    "    \"\"\"Rollout `agent` in the `environment` for 1 episode\n",
    "    Args:\n",
    "        agent (Agent): Agent/policy to generate state-conditioned actions\n",
    "        env (gym.Env): A Gym environment\n",
    "        total_steps (int, optional): Totall number of steps to rollout. Defaults to 1000.\n",
    "        render (bool, optional): Enable/disable rendering. Defaults to False.\n",
    "    Returns:\n",
    "        obs_batch (List): Batch of observations collected in the episode\n",
    "        actions_batch (List): Batch of actions performed in the episode\n",
    "        episode_reward (float): Total rewards accumulated in this episode\n",
    "    \"\"\"\n",
    "    obs, episode_reward, done, step_num = env.reset(), 0.0, False, 0\n",
    "    observations, actions = [], []\n",
    "    episode_reward = 0.0\n",
    "    while not done:\n",
    "        action = agent.get_action(obs)\n",
    "        next_obs, reward, done, info = env.step(action)\n",
    "        # Save experience\n",
    "        observations.append(\n",
    "            np.array(obs).reshape(-1)\n",
    "        )  # Convert to numpy & reshape (8, 8) to (1, 64)\n",
    "        actions.append(np.squeeze(action, 0))\n",
    "        episode_reward += reward\n",
    "\n",
    "        obs = next_obs\n",
    "        step_num += 1\n",
    "        if render:\n",
    "            env.render()\n",
    "    env.close()\n",
    "    return observations, actions, episode_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_elite_xp(trajectories, elitism_criterion):\n",
    "    \"\"\"Gather elite trajectories from the batch of trajectories\n",
    "    Args:\n",
    "        batch_trajectories (List): List of episode trajectories containing experiences (obs, actions, episode_reward)\n",
    "    Returns:\n",
    "        elite_batch_obs\n",
    "        elite_batch_actions\n",
    "        elite_reard_threshold\n",
    "    \"\"\"\n",
    "    trajectory_obs, trajectory_actions, trajectory_rewards = zip(*trajectories)\n",
    "    reward_threshold = np.percentile(trajectory_rewards, elitism_criterion)\n",
    "    indices = [\n",
    "        index\n",
    "        for index, value in enumerate(trajectory_rewards)\n",
    "        if value >= reward_threshold\n",
    "    ]\n",
    "\n",
    "    elite_trajectory_obs = [trajectory_obs[i] for i in indices]\n",
    "    elite_trajectory_actions = [trajectory_actions[i] for i in indices]\n",
    "    unpacked_elite_batch_obs = [\n",
    "        item for items in elite_trajectory_obs for item in items\n",
    "    ]\n",
    "    unpacked_elite_batch_actions = [\n",
    "        item for items in elite_trajectory_actions for item in items\n",
    "    ]\n",
    "    return (\n",
    "        np.array(unpacked_elite_batch_obs),\n",
    "        np.array(unpacked_elite_batch_actions),\n",
    "        reward_threshold,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_action_distribution(action_index, action_dim=5):\n",
    "    action_distribution = np.zeros(action_dim).astype(type(action_index))\n",
    "    action_distribution[action_index] = 1\n",
    "    # action_distribution = np.expand_dims(action_distribution, 0)\n",
    "    return action_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    env_id=\"Gridworld-v0\",\n",
    "    num_trajectory_rollouts=70,\n",
    "    elitism_criterion=70,\n",
    "    num_epochs=10,\n",
    "):\n",
    "    \"\"\"Train Agent in the given Gym `env` using approximate Cross-Entropy\n",
    "\n",
    "    Args:\n",
    "        env (str, optional): Name of the Gym environment. Defaults to \"Gridworld-v0\".\n",
    "        num_trajectory_rollouts (int, optional): Number of trajectories to rollouts/sample. Defaults to 70.\n",
    "        elitism_criterion (int, optional): Threshold (as a percentage) to choose elites. Defaults to 70.\n",
    "        num_epochs (int, optional): Number of epochs to train on the elite trajectories. Defaults to 10.\n",
    "    \"\"\"\n",
    "    num_trajectory_rollouts = num_trajectory_rollouts\n",
    "    elitism_criterion = elitism_criterion  # Percentage\n",
    "    num_epochs = num_epochs\n",
    "\n",
    "    env = gym.make(env_id)\n",
    "    agent = Agent(env.action_space.n, env.observation_space.shape)\n",
    "\n",
    "    mean_rewards = []\n",
    "    elite_reward_thresholds = []\n",
    "    for i in tqdm(range(num_epochs)):\n",
    "        trajectories = [\n",
    "            Trajectory(*rollout(agent, env)) for _ in range(num_trajectory_rollouts)\n",
    "        ]\n",
    "        _, _, batch_rewards = zip(*trajectories)\n",
    "        elite_obs, elite_actions, elite_threshold = gather_elite_xp(\n",
    "            trajectories, elitism_criterion=elitism_criterion\n",
    "        )\n",
    "        elite_action_distributions = np.array(\n",
    "            [gen_action_distribution(a.item()) for a in elite_actions]\n",
    "        )\n",
    "        elite_obs, elite_action_distributions = (\n",
    "            elite_obs.astype(\"float16\"),\n",
    "            elite_action_distributions.astype(\"float16\"),\n",
    "        )\n",
    "        agent.learn(\n",
    "            elite_obs, elite_action_distributions, batch_size=128, epochs=3, verbose=0\n",
    "        )\n",
    "        mean_rewards.append(np.mean(batch_rewards))\n",
    "        elite_reward_thresholds.append(elite_threshold)\n",
    "        print(\n",
    "            f\"Episode#:{i + 1} elite-reward-threshold:{elite_reward_thresholds[-1]:.2f} reward:{mean_rewards[-1]:.2f} \"\n",
    "        )\n",
    "\n",
    "    plt.plot(mean_rewards, \"r-\", label=\"mean_reward\")\n",
    "    plt.plot(elite_reward_thresholds, \"g--\", label=\"elites_reward_threshold\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 1/2 [00:15<00:15, 15.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode#:1 elite-reward-threshold:0.00 reward:0.00 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 2/2 [00:30<00:00, 15.13s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 2/2 [00:30<00:00, 15.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode#:2 elite-reward-threshold:0.00 reward:0.00 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    train(num_epochs=2)  # Increase value of num_epochs"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "executable": "/usr/bin/env python",
   "formats": "ipynb,py"
  },
  "kernelspec": {
   "display_name": "tfrl-cookbook",
   "language": "python",
   "name": "tfrl-cookbook"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
